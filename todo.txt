Implementation todo:
- Get types from type definitions and use these to limit search space
- Get default parameters from named parameters in functions and use these
- Result printing for classes
- Multiple successful class instances
- Once we have a set of benchmarkss, make sure performance is acceptable / improve search strategies
- Smarter search: search based on exception types (ie put in mock object, look for "class Dummy has no Meow method")
- Maybe instrument branches to ensure we're hitting all branches


Also handle:
- Side-effects (ie network)
- Infinite loops
- Runaway memory useage
- Var arg & keyword arg signatures
- Recursive data structures: run on `learn` function


Data todo:
- look at techniques in "Measuring Polymorphism in Python Programs" (they analyze 36 python libs)
- grab "top" 10? 3? python repos (maybe ranked by pypi downloads?)
- compute of all python functions in those repos, how many have full mypy annotations?
    (ideally some would and some wouldn't)
- reduced down to the ones that do, what percentage can we recover the annotation?
- of the ones that don't, what percentage can we type?



Fancy todo:
- exception based guidance
- transform dynamic checks into guesses about refinement types
- ML to guess types based on text, large python corpeses
- "magic bytes comparison"  --> grab all hardcoded values in the ast
- branching coverage maybe?
